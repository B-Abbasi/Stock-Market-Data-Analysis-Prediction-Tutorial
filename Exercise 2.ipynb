{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2 : Preprocessing - Handling Dates\n",
    "Author : Burhan Abbasi \n",
    "\n",
    "Date : 2nd February 2019\n",
    "\n",
    "Python version 3.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Disclaimer : This series of tutorials will use data hosted on Kaggle. For the purpose of this course a copy has been downloaded from the site. For latest data visit the following URL https://www.kaggle.com/timoboz/stock-data-dow-jones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir \n",
    "import pandas as pd\n",
    "\n",
    "dir_path ='Data_Set/stock-data-dow-jones/'\n",
    "files_list = [f for f in listdir(dir_path)]\n",
    "list_ = []\n",
    "\n",
    "for file_ in files_list:\n",
    "    df = pd.read_csv(dir_path+file_,index_col=None, header=0)\n",
    "    df['Stock'] =file_.split('.')[0]\n",
    "    list_.append(df)\n",
    "\n",
    "data= pd.concat(list_, axis = 0, ignore_index = True)      #Concatenating all files "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can inspect the data using columns attribute and head functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(data.columns)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did you notice there are two columns in above data showing dates? 'date' & 'label'\n",
    "Lets take a closer look at these columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data[['date','label']].info())\n",
    "print(data[['date','label']].sample(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Info() shows that number of values in both fields is same.\n",
    "\n",
    "sample() seems to show that for each sample, format is different but values are equivalent.\n",
    "\n",
    "##### Q1. Do you know that these columns represent different information or not? Give your solution below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we know fields `date` & `label` are dates! But does Python know that they are dates?\n",
    "Did you notice data types of these fields?\n",
    "\n",
    "You can use following to check data types:\n",
    "\n",
    "            data.dtypes   \n",
    "            data['date'].dtype \n",
    "            \n",
    "            \n",
    "   #to match the letter code to the dtype of the object \"O\", visit URL below \n",
    "   https://docs.scipy.org/doc/numpy1.12.0/reference/generated/numpy.dtype.kind.html#numpy.dtype.kind\n",
    "\n",
    "\n",
    "Lets check the data type for each field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Type of `Date` field is :  object\n",
      "Data Type of `Label` field is :  object\n"
     ]
    }
   ],
   "source": [
    "print('Data Type of `Date` field is : ', data['date'].dtype)\n",
    "print('Data Type of `Label` field is : ',data['label'].dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since dates are stored as Object, we should correct the format before proceeding further.\n",
    "Based on `Question 1` we continue with the belief that both fields provide same information. Lets say we choose column `label` for conversion into a `datetime` format. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now see the format of date in column /field /attribute `label`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Jan 27, 14\n",
       "1    Jan 28, 14\n",
       "2    Jan 29, 14\n",
       "3    Jan 30, 14\n",
       "4    Jan 31, 14\n",
       "Name: label, dtype: object"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['label'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use `pandas.to_datetime()` function to convert dates from `string` to `datetime` objects.\n",
    "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.to_datetime.html\n",
    "\n",
    "Read the documentation to understand details of this function. To see it in action, run the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.to_datetime('20-04-2017', format='%d-%m-%Y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell above shows usage of `pandas.to_datetime(string, format='')`,\n",
    "\n",
    "`format` is the pattern in which the string is arranged, such as '20-04-2017' or 'Feb 02,2019'\n",
    "\n",
    "The basic idea is that you need to point out which parts of the date are where and what character/puctuation is between them. See strftime directive for specific patterns http://strftime.org/\n",
    "\n",
    "##### Q2. Configure `format` in the cell below to work with date pattern in attribute `data.label`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_datetime('Jan 27, 14', format = '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the code for conversion of all rows in attribute `label` to datetime format. Use answer of `Question 2` and execute code in cell below. Inspect the output and discuss findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_datetime(data['label'], format ='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now investigate the problem before we can decide on our next step.\n",
    "\n",
    "We will create a column vector and each row will contain length of field `label` for its corresponing row. Then we will check how many different lengths of feature values exist for `label`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_t =data.label.str.len()\n",
    "_t.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we use masks to filter out values that are below a certain length. Change its value in the cell below to identify problematic cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_mask= data.label.str.len()<11\n",
    "data[_mask].dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Q3.Do we need to address above problems or can we avoid the problem altogether using an alternative? Give proposed solution in cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use your answer of `Question3` to add/replace column containing date values such that dates are in `datetime` format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['date']= "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use this field to create new features for our dataset, this is called `Feature engineering`. It is the process of using domain knowledge of the data to create features that can help machine learning algorithms in indetifying underlying patterns. If feature engineering is done correctly, it increases the predictive capabilities of machine learning algorithms.\n",
    "\n",
    "##### Q4. Create following new features and add to dataset\n",
    "    Year i.e. 2005, 2006, 2007, ...\n",
    "    Month i.e. 1,2,3, ..., 12 or Jan, Feb, Mar, ... Dec\n",
    "    DayOfMonth i.e. 1,2,3,4,5...30,31\n",
    "    WeekDay i.e. Monday, Tuesday, Wednesday, Thursday, Friday, Saturday, Sunday\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
